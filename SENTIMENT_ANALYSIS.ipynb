{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SENTIMENT ANALYSIS"
      ],
      "metadata": {
        "id": "PqaP5MJkznY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### IMPORTS"
      ],
      "metadata": {
        "id": "I_Co0q_N5dZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import re\n",
        "import json"
      ],
      "metadata": {
        "id": "m4vDh50Wzpe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT THE ROBERTA MODEL FOR SENTIMENT ANALYSIS\n",
        "from transformers import pipeline\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\",max_length=512, truncation=True)\n",
        "print(sentiment_analysis(\"I love this!\"))"
      ],
      "metadata": {
        "id": "Q8R_x77tzs1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE THE FOLLOWING DIRECTORY IF YOU WANT TO REPRODUCE THE RESULTS\n",
        "drive_directory = \"/content/drive/MyDrive/INNOVATION-PROJECT/\""
      ],
      "metadata": {
        "id": "l0b8jU4q7PcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PROCESSING FUNCTIONS"
      ],
      "metadata": {
        "id": "MH8x9IRU5jJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(x):\n",
        "\n",
        "    \"\"\"\n",
        "    Inputs: x --> String to be cleaned\n",
        "    Outputs: clean string\n",
        "\n",
        "    \"\"\"\n",
        "    x = re.sub(r\"\\\\n\",\"\",x)\n",
        "    x = re.sub(r\"\\\\t\",\"\",x)\n",
        "    x = re.sub(r'\"', \"\",x)\n",
        "    #x = re.sub(r\"https?:\\/\\/.*?[\\s+]\",\"\",x) # remove URLs\n",
        "    x = re.sub(r\"([a-zA-Z0-9_\\-\\.]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})\",\"\",x) # Remove emails\n",
        "    return x"
      ],
      "metadata": {
        "id": "y8uz1OtL0hpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_df(df,date_column, rating_column, text_column):\n",
        "\n",
        "    \"\"\"\n",
        "    Inputs: df --> pandas DataFrame to be cleaned\n",
        "            date_column --> name of the column containing the data information\n",
        "            rating_column --> name of the column containing the rating information\n",
        "            text_column --> name of the column containing the reviews\n",
        "\n",
        "    Outputs: clean dataframe\n",
        "\n",
        "    \"\"\"\n",
        "  #clean text\n",
        "  df[text_column] = df[text_column].fillna(0)\n",
        "  df = df[df[text_column] != 0].reset_index(drop = True)\n",
        "  df[text_column] = [preprocess(x) for x in df[text_column]]\n",
        "\n",
        "  #clean the dates and put them in pd.date_time format\n",
        "  clean_dates = []\n",
        "  for date in df[date_column]:\n",
        "    try:\n",
        "      date = pd.to_datetime(date,format=\"%b %d %Y\")\n",
        "    except ValueError:\n",
        "      date = pd.to_datetime(date)\n",
        "    clean_dates.append(date)\n",
        "  df[date_column] = clean_dates\n",
        "\n",
        "  #clean the rating - store it as a float number\n",
        "  df[rating_column] = df[rating_column].astype(str)\n",
        "  df[rating_column] = [float(re.sub(\"\\sstars\",\"\",x)) for x in df[rating_column]]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "cSqP1wLo0BIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sentiment(df,text_column,id_batch):\n",
        "\n",
        "    \"\"\"\n",
        "    Inputs: df --> pandas DataFrame on which sentiment analysis is performed\n",
        "            text_column --> name of the column containing the reviews\n",
        "            id_batch --> Id of the batch in string format, e.g. \"798\"\n",
        "\n",
        "    Outputs: list containing sentiment scores and labels for all reviews\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "  batches = list(chunks(df[text_column].tolist(),500))\n",
        "\n",
        "  for i in range(len(batches)): # perform sentiment analysis on small batches of 500 reviews at a time to save RAM, and save them\n",
        "    scores = sentiment_analysis(batches[i])\n",
        "    with open(drive_directory + f\"scores{id_batch}_{i}.json\",\"w\") as f:\n",
        "      json.dump(scores,f)\n",
        "\n",
        "  sentiment = []\n",
        "  for i in range(len(batches)): # read the saved batches and join them\n",
        "    with open(drive_directory + f\"scores{id_batch}_{i}.json\",\"r\") as file:\n",
        "      sentiment += json.load(file)\n",
        "\n",
        "  return sentiment"
      ],
      "metadata": {
        "id": "WsVge6HS0LS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sentiment(df,sentiment_list):\n",
        "\n",
        "    \"\"\"\n",
        "    Inputs: df --> pandas DataFrame on which we want to add the sentiment scores\n",
        "            sentiment_list --> list containing the sentiment score for each review\n",
        "\n",
        "\n",
        "    Outputs: dataframe with new column contaning sentiment information\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "  df = df.reset_index(drop = True)\n",
        "  df[\"sentiment\"] = sentiment_list\n",
        "  df[\"sentiment_score\"] = df[\"sentiment\"].apply(lambda x: x.get(\"score\"))\n",
        "  df[\"sentiment_label\"] = df[\"sentiment\"].apply(lambda x: x.get(\"label\"))\n",
        "  df[\"sentiment_score\"] = [df.sentiment_score[x] if df.sentiment_label[x] == \"POSITIVE\" else 1 - df.sentiment_score[x] for x in range(len(df))] # change the score to be close to 0 if negative\n",
        "  df = df.reset_index(drop = True).drop(\"Unnamed: 0\",axis = 1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "39DbztMK6htv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FIRST BATCH"
      ],
      "metadata": {
        "id": "gf4UjWoI0s8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews300 = pd.read_csv(drive_directory + \"reviews300.csv\")\n",
        "current_300 = clean_df(reviews300,\"Date\",\"Rating\",\"Text\")\n",
        "sentiment_300 = create_sentiment(current_300,\"Text\",\"300\")\n",
        "final487 = add_sentiment(current_300, sentiment_300)\n",
        "final487.to_csv(drive_directory + \"reviews300-487clean.csv\")"
      ],
      "metadata": {
        "id": "RtJZ8WoR0VQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SECOND BATCH"
      ],
      "metadata": {
        "id": "g2VuTuQV0vOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews487 = pd.read_csv(drive_directory + \"reviews300.csv\")\n",
        "current_487 = clean_df(reviews300,\"Date\",\"Rating\",\"Text\")\n",
        "current_487 = current487.loc[5431:,:].reset_index(drop = True)\n",
        "sentiment_487 = create_sentiment(current_487,\"Text\",\"487\")\n",
        "final487 = add_sentiment(current_487, sentiment_487)\n",
        "final487.to_csv(drive_directory + \"reviews300-487clean.csv\")"
      ],
      "metadata": {
        "id": "QfGUCTTm0wkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### THIRD BATCH"
      ],
      "metadata": {
        "id": "VPSbM5ML0xGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews798 = pd.read_csv(drive_directory + \"reviews300.csv\")\n",
        "current_798 = clean_df(reviews300,\"Date\",\"Rating\",\"Text\")\n",
        "current_index = 5431 + 3419\n",
        "current_798 = current_df.loc[current_index:]\n",
        "sentiment_798 = create_sentiment(current_798,\"Text\",\"798\")\n",
        "final798 = add_sentiment(current_798, sentiment_798)\n",
        "final798.to_csv(drive_directory + \"reviews487-798clean.csv\")"
      ],
      "metadata": {
        "id": "hiNHpdQS0ySZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FOURTH BATCH"
      ],
      "metadata": {
        "id": "xMaujHNn0y-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews1000 = pd.read_csv(drive_directory + \"reviews1000.csv\")\n",
        "current_1000 = clean_df(reviews1000,\"Date\",\"Rating\",\"Text\")\n",
        "sentiment_1000 = create_sentiment(current_1000, \"Text\",1000)\n",
        "final1000 = add_sentiment(current_1000, sentiment_1000)\n",
        "final1000.to_csv( drive_directory + \"reviews798-1000clean.csv\")"
      ],
      "metadata": {
        "id": "hh-F7wlb00E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FIFTH BATCH"
      ],
      "metadata": {
        "id": "YoQZfsRM3MNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews1250 = pd.read_csv(drive_directory + \"reviews1250.csv\")\n",
        "reviews1250.Text = reviews1250.Text.fillna(0)\n",
        "current_1250 = reviews1250[reviews1250.Text != 0].reset_index(drop = True).loc[3368:]\n",
        "current_df = current_1250[current_1250.Date != \"Date\"]\n",
        "current_1250 = clean_df(current_1250,\"Date\",\"Rating\",\"Text\")\n",
        "sentiment_1250 = create_sentiment(current_1250, \"Text\",\"1250\")\n",
        "final1250 = add_sentiment(current_1250, sentiment_1250)\n",
        "final1250.to_csv(drive_directory + \"reviews1000-1250clean.csv\")"
      ],
      "metadata": {
        "id": "QY2AGRTU3LPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SIXTH BATCH - had some problems with duplicates in the previous batch, so we add an extra step to ensure to process only new data"
      ],
      "metadata": {
        "id": "4xH-Nmve34Cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews1466 = pd.read_csv( drive_directory + \"reviews1466.csv\")\n",
        "reviews1466.Text = reviews1466.Text.fillna(0)\n",
        "reviews1466 = reviews1466[reviews1466.Text != 0]"
      ],
      "metadata": {
        "id": "sFFuNmwz35FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch1 = pd.read_csv(drive_directory + \"reviews300clean.csv\")\n",
        "batch2 = pd.read_csv(drive_directory + \"reviews300-487clean.csv\")\n",
        "batch3 = pd.read_csv(drive_directory + \"reviews487-798clean.csv\")\n",
        "batch4 = pd.read_csv(drive_directory + \"reviews798-1000clean.csv\")\n",
        "batch5 = pd.read_csv(drive_directory + \"reviews1000-1250clean.csv\")\n",
        "\n",
        "r1 = batch1[\"Review ID\"].unique()\n",
        "r2 = batch2[\"Review ID\"].unique()\n",
        "r3 = batch3[\"Review ID\"].unique()\n",
        "r4 = batch4[\"Review ID\"].unique()\n",
        "r5 = batch5[\"Review ID\"].unique()\n",
        "\n",
        "# TAKE ONLY REVIEWS THAT WERE NOT IN THE PREVIOUS BATCH\n",
        "s = set().union(r1,r2,r3,r4,r5)\n",
        "reviews1466 = reviews1466[~reviews1466[\"Review ID\"].isin(s)]"
      ],
      "metadata": {
        "id": "6iV_WWLJ4Cqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_1466 = clean_df(reviews1466,\"Date\",\"Rating\",\"Text\")\n",
        "sentiment_1466 = create_sentiment(current_1466,\"Text\",\"1466\")\n",
        "final1466 = add_sentiment(current_1466, sentiment_1466)\n",
        "final1466.to_csv(drive_directory + \"reviews1250-1466clean.csv\")"
      ],
      "metadata": {
        "id": "htdXCQa44qPG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}